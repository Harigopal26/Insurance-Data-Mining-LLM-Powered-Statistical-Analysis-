{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "869972ee-ced7-4441-8127-ad7a1c62f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b249cd7-7523-4499-bf21-34e48d600914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_name(column):\n",
    "    \"\"\"Helper function to clean column names\"\"\"\n",
    "    return str(column).strip().lower().replace(\"'\", \"\").replace('\"', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ed2ef9e-4190-4c54-9b79-63f3f8f125d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnivariateAnalyzer:\n",
    "    def __init__(self, data):\n",
    "        \"\"\"Initialize with pandas DataFrame\"\"\"\n",
    "        self.data = data\n",
    "        self.numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "        self.categorical_cols = data.select_dtypes(exclude=[np.number]).columns\n",
    "        \n",
    "    def compute_summary_statistics(self, column):\n",
    "        \"\"\"Compute comprehensive summary statistics\"\"\"\n",
    "        try:\n",
    "            column = clean_column_name(column)\n",
    "            data = self.data[column].dropna()\n",
    "            \n",
    "            stats_dict = {\n",
    "                'mean': float(np.mean(data)),\n",
    "                'median': float(np.median(data)),\n",
    "                'std': float(np.std(data)),\n",
    "                'var': float(np.var(data)),\n",
    "                'skew': float(stats.skew(data)),\n",
    "                'kurtosis': float(stats.kurtosis(data)),\n",
    "                'iqr': float(stats.iqr(data)),\n",
    "                'range': float(np.ptp(data)),\n",
    "                'min': float(data.min()),\n",
    "                'max': float(data.max()),\n",
    "                'q1': float(np.percentile(data, 25)),\n",
    "                'q3': float(np.percentile(data, 75)),\n",
    "                'count': int(len(data)),\n",
    "                'missing': int(self.data[column].isna().sum())\n",
    "            }\n",
    "            \n",
    "            formatted_stats = {\n",
    "                k: f\"{v:.2f}\" if isinstance(v, float) else v \n",
    "                for k, v in stats_dict.items()\n",
    "            }\n",
    "            \n",
    "            # Add distribution type\n",
    "            _, p_value = stats.normaltest(data)\n",
    "            formatted_stats['distribution'] = 'Normal' if p_value > 0.05 else 'Non-normal'\n",
    "            \n",
    "            return formatted_stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error computing statistics for column {column}: {str(e)}\"\n",
    "    \n",
    "    def analyze_by_group(self, numeric_col, categorical_col):\n",
    "        \"\"\"Analyze numeric variables split by categorical variables\"\"\"\n",
    "        try:\n",
    "            numeric_col = clean_column_name(numeric_col)\n",
    "            categorical_col = clean_column_name(categorical_col)\n",
    "            \n",
    "            if numeric_col not in self.data.columns:\n",
    "                return f\"Error: Column '{numeric_col}' not found in dataset\"\n",
    "            if categorical_col not in self.data.columns:\n",
    "                return f\"Error: Column '{categorical_col}' not found in dataset\"\n",
    "            \n",
    "            grouped_stats = {}\n",
    "            group_summaries = {}\n",
    "            \n",
    "            for category in self.data[categorical_col].unique():\n",
    "                subset = self.data[self.data[categorical_col] == category][numeric_col]\n",
    "                stats_dict = {\n",
    "                    'count': len(subset),\n",
    "                    'mean': float(np.mean(subset)),\n",
    "                    'median': float(np.median(subset)),\n",
    "                    'std': float(np.std(subset)),\n",
    "                    'min': float(subset.min()),\n",
    "                    'max': float(subset.max()),\n",
    "                    'q1': float(np.percentile(subset, 25)),\n",
    "                    'q3': float(np.percentile(subset, 75)),\n",
    "                    'iqr': float(np.percentile(subset, 75) - np.percentile(subset, 25))\n",
    "                }\n",
    "                \n",
    "                grouped_stats[str(category)] = {\n",
    "                    k: f\"{v:.2f}\" if isinstance(v, float) else v \n",
    "                    for k, v in stats_dict.items()\n",
    "                }\n",
    "                \n",
    "                group_summaries[str(category)] = {\n",
    "                    'size': len(subset),\n",
    "                    'percentage': f\"{(len(subset) / len(self.data)) * 100:.1f}%\"\n",
    "                }\n",
    "            \n",
    "            groups = [self.data[self.data[categorical_col] == cat][numeric_col].dropna() \n",
    "                     for cat in self.data[categorical_col].unique()]\n",
    "            \n",
    "            if len(groups) == 2:\n",
    "                stat, p_value = stats.ttest_ind(*groups)\n",
    "                test_name = \"t-test\"\n",
    "            else:\n",
    "                stat, p_value = stats.f_oneway(*groups)\n",
    "                test_name = \"ANOVA\"\n",
    "            \n",
    "            ss_between = sum(len(g) * ((np.mean(g) - np.mean(self.data[numeric_col])) ** 2) for g in groups)\n",
    "            ss_total = sum((self.data[numeric_col] - np.mean(self.data[numeric_col])) ** 2)\n",
    "            eta_squared = ss_between / ss_total if ss_total != 0 else 0\n",
    "            \n",
    "            return {\n",
    "                'group_statistics': grouped_stats,\n",
    "                'group_summaries': group_summaries,\n",
    "                'between_group_comparison': {\n",
    "                    'test_type': test_name,\n",
    "                    'statistic': f\"{stat:.3f}\",\n",
    "                    'p_value': f\"{p_value:.3f}\",\n",
    "                    'significant_difference': 'Yes' if p_value < 0.05 else 'No',\n",
    "                    'effect_size': f\"{eta_squared:.3f}\"\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error in group analysis: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3504f408-cc6a-4f33-b19e-926e951a8727",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMAnalyzer:\n",
    "    def __init__(self, api_key):\n",
    "        \"\"\"Initialize with OpenAI API key\"\"\"\n",
    "        self.llm = OpenAI(openai_api_key=api_key, temperature=0)\n",
    "        self.embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "        self.vector_store = None\n",
    "        \n",
    "    def setup_rag(self, pdf_path):\n",
    "        \"\"\"Setup RAG system with PDF document\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(pdf_path):\n",
    "                loader = PyPDFLoader(pdf_path)\n",
    "                documents = loader.load()\n",
    "                text_splitter = CharacterTextSplitter(\n",
    "                    chunk_size=1000,\n",
    "                    chunk_overlap=200\n",
    "                )\n",
    "                texts = text_splitter.split_documents(documents)\n",
    "                self.vector_store = FAISS.from_documents(texts, self.embeddings)\n",
    "                return \"RAG system initialized successfully\"\n",
    "            else:\n",
    "                return f\"Error: PDF file '{pdf_path}' not found\"\n",
    "        except Exception as e:\n",
    "            return f\"Error setting up RAG system: {str(e)}\"\n",
    "        \n",
    "    def query_rag(self, query):\n",
    "        \"\"\"Query the RAG system with detailed context\"\"\"\n",
    "        try:\n",
    "            if self.vector_store is None:\n",
    "                return \"RAG system not initialized. Please load a PDF first.\"\n",
    "                \n",
    "            relevant_docs = self.vector_store.similarity_search(query, k=3)\n",
    "            context = \"\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "            \n",
    "            prompt = f\"\"\"\n",
    "            Context: {context}\n",
    "            \n",
    "            Query: {query}\n",
    "            \n",
    "            Based on the context above and the insurance dataset, provide a detailed analysis:\n",
    "            \"\"\"\n",
    "            \n",
    "            response = self.llm(prompt)\n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error querying RAG system: {str(e)}\"\n",
    "        \n",
    "    def create_tools(self, univariate_analyzer):\n",
    "        \"\"\"Create tools for the agent with improved descriptions\"\"\"\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"Univariate Analysis\",\n",
    "                func=lambda x: univariate_analyzer.compute_summary_statistics(x),\n",
    "                description=\"Get statistical analysis of a single column. Input: column name (e.g., bmi, age, charges)\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"Group Analysis\",\n",
    "                func=lambda x: univariate_analyzer.analyze_by_group(*[col.strip() for col in x.split(',')]),\n",
    "                description=\"Compare statistics across groups. Input format: 'numeric_column,categorical_column' (e.g., charges,smoker)\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"RAG Query\",\n",
    "                func=lambda x: self.query_rag(x),\n",
    "                description=\"Query the PDF documentation for domain knowledge and insights. Input: natural language question\"\n",
    "            )\n",
    "        ]\n",
    "        return tools\n",
    "        \n",
    "    def setup_agent(self, tools):\n",
    "        \"\"\"Initialize LangChain agent with verbose output\"\"\"\n",
    "        return initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=\"zero-shot-react-description\",\n",
    "            verbose=True,\n",
    "            max_iterations=5\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e99d22e-7346-4992-9442-6d453ba7be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional helper function for running agent queries\n",
    "def run_agent_queries(univariate_analyzer, llm_analyzer, agent, data):\n",
    "    \"\"\"Run all queries including statistical analysis and RAG queries\"\"\"\n",
    "    # Statistical Analysis Queries\n",
    "    queries = [\n",
    "        {\n",
    "            \"query\": \"Analyze the statistics of the bmi column\",\n",
    "            \"expected_tool\": \"Univariate Analysis\",\n",
    "            \"backup_func\": lambda: univariate_analyzer.compute_summary_statistics(\"bmi\")\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"Compare bmi statistics between different sex groups\",\n",
    "            \"expected_tool\": \"Group Analysis\",\n",
    "            \"backup_func\": lambda: univariate_analyzer.analyze_by_group(\"bmi\", \"sex\")\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"What's the distribution of charges for smokers vs non-smokers?\",\n",
    "            \"expected_tool\": \"Group Analysis\",\n",
    "            \"backup_func\": lambda: univariate_analyzer.analyze_by_group(\"charges\", \"smoker\")\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"Show me the age distribution statistics\",\n",
    "            \"expected_tool\": \"Univariate Analysis\",\n",
    "            \"backup_func\": lambda: univariate_analyzer.compute_summary_statistics(\"age\")\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nRunning Statistical Analysis Queries:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, query_info in enumerate(queries, 1):\n",
    "        print(f\"\\nQuery {i}: {query_info['query']}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        try:\n",
    "            result = agent.run(query_info['query'])\n",
    "            print(\"\\nAnalysis Result (via Agent):\")\n",
    "            print_formatted_results(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nFalling back to direct analysis...\")\n",
    "            try:\n",
    "                result = query_info['backup_func']()\n",
    "                print(\"\\nAnalysis Result (via Backup):\")\n",
    "                print_formatted_results(result)\n",
    "            except Exception as backup_error:\n",
    "                print(f\"Analysis failed: {str(backup_error)}\")\n",
    "            \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "    # RAG Queries\n",
    "    rag_queries = [\n",
    "        \"What are the key factors affecting insurance charges?\",\n",
    "        \"How does lifestyle impact insurance premiums?\",\n",
    "        \"What are the best practices for risk assessment in insurance?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nRunning RAG Queries:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, query in enumerate(rag_queries, 1):\n",
    "        print(f\"\\nRAG Query {i}: {query}\")\n",
    "        print(\"-\" * 80)\n",
    "        result = llm_analyzer.query_rag(query)\n",
    "        print(\"\\nRAG Analysis Result:\")\n",
    "        print(result)\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3357e845-1ceb-4170-86db-8ed7a91790e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4066dfce-a3bb-4ec1-b268-ca52c8aec38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_integrated_report(results, filename=\"integrated_analysis_report.txt\"):\n",
    "    \"\"\"Generate comprehensive report with statistical and LLM analysis\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            # Header\n",
    "            f.write(f\"Integrated Analysis Report\\n\")\n",
    "            f.write(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "            \n",
    "            # Statistical Analysis Section\n",
    "            f.write(\"1. STATISTICAL ANALYSIS\\n\")\n",
    "            f.write(\"-\" * 80 + \"\\n\\n\")\n",
    "            \n",
    "            # Write each analysis result\n",
    "            for analysis_name, result in results['statistical_results'].items():\n",
    "                f.write(f\"\\n{analysis_name}:\\n\")\n",
    "                f.write(\"-\" * 40 + \"\\n\")\n",
    "                \n",
    "                if isinstance(result, dict):\n",
    "                    for key, value in result.items():\n",
    "                        if isinstance(value, dict):\n",
    "                            f.write(f\"\\n{key}:\\n\")\n",
    "                            for subkey, subvalue in value.items():\n",
    "                                f.write(f\"  {subkey}: {subvalue}\\n\")\n",
    "                        else:\n",
    "                            f.write(f\"{key}: {value}\\n\")\n",
    "                else:\n",
    "                    f.write(str(result) + \"\\n\")\n",
    "            \n",
    "            # RAG Analysis Section\n",
    "            f.write(\"\\n2. RAG ANALYSIS\\n\")\n",
    "            f.write(\"-\" * 80 + \"\\n\\n\")\n",
    "            \n",
    "            for query, response in results['rag_results'].items():\n",
    "                f.write(f\"Query: {query}\\n\")\n",
    "                f.write(f\"Response: {response}\\n\\n\")\n",
    "            \n",
    "            # Conclusions Section\n",
    "            f.write(\"\\n3. CONCLUSIONS\\n\")\n",
    "            f.write(\"-\" * 80 + \"\\n\\n\")\n",
    "            \n",
    "            # Generate and write conclusions\n",
    "            conclusions = generate_conclusions(results)\n",
    "            f.write(conclusions)\n",
    "            \n",
    "            f.write(\"\\n\\n\" + \"=\" * 80 + \"\\n\")\n",
    "        \n",
    "        return \"Integrated report generated successfully\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error generating report: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8257db7-71aa-4410-9d8f-a401b3d2083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_conclusions(results):\n",
    "    \"\"\"Generate conclusions based on the analysis results\"\"\"\n",
    "    conclusions = []\n",
    "    \n",
    "    # Analyze BMI distribution\n",
    "    if 'BMI Analysis' in results['statistical_results']:\n",
    "        bmi_stats = results['statistical_results']['BMI Analysis']\n",
    "        conclusions.append(f\"BMI Distribution: The average BMI is {bmi_stats.get('mean', 'N/A')} \"\n",
    "                         f\"with a standard deviation of {bmi_stats.get('std', 'N/A')}.\")\n",
    "    \n",
    "    # Analyze group differences\n",
    "    if 'Sex Group Comparison' in results['statistical_results']:\n",
    "        group_comparison = results['statistical_results']['Sex Group Comparison']\n",
    "        if 'between_group_comparison' in group_comparison:\n",
    "            comparison = group_comparison['between_group_comparison']\n",
    "            conclusions.append(f\"Group Differences: {comparison.get('test_type', 'Statistical')} analysis shows \"\n",
    "                             f\"{'significant' if comparison.get('significant_difference') == 'Yes' else 'no significant'} \"\n",
    "                             f\"differences between groups (p-value: {comparison.get('p_value', 'N/A')}).\")\n",
    "    \n",
    "    # Add overall conclusion\n",
    "    conclusions.append(\"\\nOverall Assessment:\")\n",
    "    conclusions.append(\"The analysis reveals patterns in insurance data that can be valuable for risk assessment \"\n",
    "                      \"and policy pricing. Further investigation of specific factors may be warranted based on \"\n",
    "                      \"the observed relationships.\")\n",
    "    \n",
    "    return \"\\n\".join(conclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c065a0e-3bd2-4e74-8a50-452118cacac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis_with_report(univariate_analyzer, llm_analyzer, agent):\n",
    "    \"\"\"Run analysis and generate report\"\"\"\n",
    "    results = {\n",
    "        'statistical_results': {},\n",
    "        'rag_results': {}\n",
    "    }\n",
    "    \n",
    "    # Run statistical analyses\n",
    "    results['statistical_results']['BMI Analysis'] = univariate_analyzer.compute_summary_statistics('bmi')\n",
    "    results['statistical_results']['Sex Group Comparison'] = univariate_analyzer.analyze_by_group('bmi', 'sex')\n",
    "    results['statistical_results']['Smoker Charges Analysis'] = univariate_analyzer.analyze_by_group('charges', 'smoker')\n",
    "    results['statistical_results']['Age Distribution'] = univariate_analyzer.compute_summary_statistics('age')\n",
    "    \n",
    "    # Run RAG queries\n",
    "    rag_queries = [\n",
    "        \"What are the key factors affecting insurance charges?\",\n",
    "        \"How does lifestyle impact insurance premiums?\",\n",
    "        \"What are the best practices for risk assessment in insurance?\"\n",
    "    ]\n",
    "    \n",
    "    for query in rag_queries:\n",
    "        results['rag_results'][query] = llm_analyzer.query_rag(query)\n",
    "    \n",
    "    # Generate report\n",
    "    report_status = generate_integrated_report(results)\n",
    "    print(report_status)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6c85c76-22be-4935-b33c-d27ccac9694e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lq/2_6xns4s5kdf1420gt7mfn_c0000gn/T/ipykernel_40047/1879272235.py:4: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  self.llm = OpenAI(openai_api_key=api_key, temperature=0)\n",
      "/var/folders/lq/2_6xns4s5kdf1420gt7mfn_c0000gn/T/ipykernel_40047/1879272235.py:5: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  self.embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 28 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzers initialized\n",
      "RAG setup status: RAG system initialized successfully\n",
      "Agent setup completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lq/2_6xns4s5kdf1420gt7mfn_c0000gn/T/ipykernel_40047/1879272235.py:72: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use :meth:`~Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc.` instead.\n",
      "  return initialize_agent(\n",
      "/var/folders/lq/2_6xns4s5kdf1420gt7mfn_c0000gn/T/ipykernel_40047/1879272235.py:43: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = self.llm(prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrated report generated successfully\n",
      "Analysis completed and report generated\n",
      "\n",
      "Running Statistical Analysis Queries:\n",
      "================================================================================\n",
      "\n",
      "Query 1: Analyze the statistics of the bmi column\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lq/2_6xns4s5kdf1420gt7mfn_c0000gn/T/ipykernel_40047/3621312449.py:36: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = agent.run(query_info['query'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I should use univariate analysis to get the statistics of a single column\n",
      "Action: Univariate Analysis\n",
      "Action Input: bmi\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'mean': '30.66', 'median': '30.40', 'std': '6.10', 'var': '37.16', 'skew': '0.28', 'kurtosis': '-0.06', 'iqr': '8.40', 'range': '37.17', 'min': '15.96', 'max': '53.13', 'q1': '26.30', 'q3': '34.69', 'count': 1338, 'missing': 0, 'distribution': 'Non-normal'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the statistics of the bmi column\n",
      "Final Answer: The mean bmi is 30.66, the median bmi is 30.40, and the standard deviation is 6.10.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Analysis Result (via Agent):\n",
      "\n",
      "Falling back to direct analysis...\n",
      "\n",
      "Analysis Result (via Backup):\n",
      "Analysis failed: name 'print_formatted_results' is not defined\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Query 2: Compare bmi statistics between different sex groups\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use Group Analysis to compare the bmi column across the sex column\n",
      "Action: Group Analysis\n",
      "Action Input: bmi, sex\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m{'group_statistics': {'female': {'count': 662, 'mean': '30.38', 'median': '30.11', 'std': '6.04', 'min': '16.82', 'max': '48.07', 'q1': '26.12', 'q3': '34.31', 'iqr': '8.19'}, 'male': {'count': 676, 'mean': '30.94', 'median': '30.69', 'std': '6.14', 'min': '15.96', 'max': '53.13', 'q1': '26.41', 'q3': '34.99', 'iqr': '8.58'}}, 'group_summaries': {'female': {'size': 662, 'percentage': '49.5%'}, 'male': {'size': 676, 'percentage': '50.5%'}}, 'between_group_comparison': {'test_type': 't-test', 'statistic': '-1.697', 'p_value': '0.090', 'significant_difference': 'No', 'effect_size': '0.002'}}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should also check the RAG Query for any additional insights on bmi and sex\n",
      "Action: RAG Query\n",
      "Action Input: \"What is the relationship between bmi and sex?\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m\n",
      "There appears to be a weak relationship between BMI and sex. From the scatter plot, there is no clear pattern or direction between the two variables, indicating a weak correlation. This suggests that sex does not have a significant impact on BMI. However, there are some outliers in the data, which could potentially skew the results.\n",
      "\n",
      "When examining the numerical summaries for each variable, the mean BMI for males is slightly higher than that of females (30.8 vs 30.4). However, the standard deviation for both groups is similar, indicating that there is not a significant difference in the spread of BMI between males and females.\n",
      "\n",
      "In terms of the distribution of BMI, both males and females have a similar shape, with a slight right skew. This suggests that the majority of individuals fall within a similar range of BMI, regardless of their sex.\n",
      "\n",
      "Overall, while there may be a slight difference in the mean BMI between males and females, the weak relationship between BMI and sex suggests that sex does not play a significant role in determining BMI. Other factors, such as age and lifestyle, may have a stronger influence on BMI.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The relationship between BMI and sex is weak, with a slightly higher mean BMI for males compared to females. However, sex does not have a significant impact on BMI and other factors may play a stronger role in determining BMI.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Analysis Result (via Agent):\n",
      "\n",
      "Falling back to direct analysis...\n",
      "\n",
      "Analysis Result (via Backup):\n",
      "Analysis failed: name 'print_formatted_results' is not defined\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Query 3: What's the distribution of charges for smokers vs non-smokers?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use Group Analysis to compare the charges column across the smoker and non-smoker groups\n",
      "Action: Group Analysis\n",
      "Action Input: 'charges,smoker'\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m{'group_statistics': {'yes': {'count': 274, 'mean': '32050.23', 'median': '34456.35', 'std': '11520.47', 'min': '12829.46', 'max': '63770.43', 'q1': '20826.24', 'q3': '41019.21', 'iqr': '20192.96'}, 'no': {'count': 1064, 'mean': '8434.27', 'median': '7345.41', 'std': '5990.96', 'min': '1121.87', 'max': '36910.61', 'q1': '3986.44', 'q3': '11362.89', 'iqr': '7376.45'}}, 'group_summaries': {'yes': {'size': 274, 'percentage': '20.5%'}, 'no': {'size': 1064, 'percentage': '79.5%'}}, 'between_group_comparison': {'test_type': 't-test', 'statistic': '46.665', 'p_value': '0.000', 'significant_difference': 'Yes', 'effect_size': '0.620'}}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look at the mean and median charges for smokers and non-smokers to see if there is a significant difference\n",
      "Action: Univariate Analysis\n",
      "Action Input: 'charges'\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'mean': '13270.42', 'median': '9382.03', 'std': '12105.48', 'var': '146542766.49', 'skew': '1.51', 'kurtosis': '1.60', 'iqr': '11899.63', 'range': '62648.55', 'min': '1121.87', 'max': '63770.43', 'q1': '4740.29', 'q3': '16639.91', 'count': 1338, 'missing': 0, 'distribution': 'Non-normal'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should also look at the percentage of smokers and non-smokers in the dataset to see if the groups are balanced\n",
      "Action: Group Analysis\n",
      "Action Input: 'smoker'\u001b[0m\n",
      "Falling back to direct analysis...\n",
      "\n",
      "Analysis Result (via Backup):\n",
      "Analysis failed: name 'print_formatted_results' is not defined\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Query 4: Show me the age distribution statistics\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use Univariate Analysis to get the statistics for the age column\n",
      "Action: Univariate Analysis\n",
      "Action Input: age\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'mean': '39.21', 'median': '39.00', 'std': '14.04', 'var': '197.25', 'skew': '0.06', 'kurtosis': '-1.24', 'iqr': '24.00', 'range': '46.00', 'min': '18.00', 'max': '64.00', 'q1': '27.00', 'q3': '51.00', 'count': 1338, 'missing': 0, 'distribution': 'Non-normal'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The age distribution statistics are: mean=39.21, median=39.00, std=14.04, var=197.25, skew=0.06, kurtosis=-1.24, iqr=24.00, range=46.00, min=18.00, max=64.00, q1=27.00, q3=51.00, count=1338, missing=0, distribution=Non-normal.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Analysis Result (via Agent):\n",
      "\n",
      "Falling back to direct analysis...\n",
      "\n",
      "Analysis Result (via Backup):\n",
      "Analysis failed: name 'print_formatted_results' is not defined\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Running RAG Queries:\n",
      "================================================================================\n",
      "\n",
      "RAG Query 1: What are the key factors affecting insurance charges?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "RAG Analysis Result:\n",
      "\n",
      "The key factors affecting insurance charges can be identified through a thorough analysis of the insurance dataset. These factors include smoking status, region, age, and BMI.\n",
      "\n",
      "1. Smoking Status: The analysis shows that smokers tend to pay significantly higher insurance charges compared to non-smokers. This is because smoking is associated with various health issues, leading to higher medical costs and ultimately higher insurance charges. Additionally, the analysis also reveals that smokers experience a bigger increase in insurance charges as they age compared to non-smokers.\n",
      "\n",
      "2. Region: The region where a person lives also plays a role in determining their insurance charges. The analysis shows that smokers from all regions tend to pay higher insurance charges compared to non-smokers. However, the data also suggests that smokers from the 'other' region tend to pay the highest charges. This could be due to various factors such as lifestyle, access to healthcare, and prevalence of smoking in that region.\n",
      "\n",
      "3. Age: As people get older, they tend to pay more for insurance. This is because older individuals often require more medical care, leading to higher insurance costs. The analysis shows a positive linear relationship between age and charges, with older individuals paying significantly higher charges compared to younger ones.\n",
      "\n",
      "4. BMI: The analysis also reveals that BMI (body mass\n",
      "================================================================================\n",
      "\n",
      "RAG Query 2: How does lifestyle impact insurance premiums?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "RAG Analysis Result:\n",
      "\n",
      "Lifestyle can have a significant impact on insurance premiums. In this analysis, we will focus on the variables of smoking status, region, charges, BMI, and age to understand how lifestyle choices can affect insurance costs.\n",
      "\n",
      "First, we will look at the relationship between smoking status and insurance charges. From the scatterplot, we can see that smokers tend to pay higher insurance charges compared to non-smokers. This is because smoking is associated with a higher risk of health issues, leading to more medical care and higher insurance costs. Additionally, as smokers age, they experience a bigger increase in insurance charges compared to non-smokers.\n",
      "\n",
      "Next, we will examine the impact of region on insurance charges. While there doesn't seem to be a significant difference in charges based on region, we can see that smokers from all regions tend to pay higher insurance charges compared to non-smokers. This suggests that smoking status plays a key role in determining insurance costs, regardless of where a person lives.\n",
      "\n",
      "Moving on to BMI, we can see from the scatterplot that there is no clear trend or direction between BMI and insurance charges. However, there is a weak positive relationship between BMI and age, indicating that as people age, their BMI tends to increase, potentially leading to higher insurance costs.\n",
      "\n",
      "When looking at\n",
      "================================================================================\n",
      "\n",
      "RAG Query 3: What are the best practices for risk assessment in insurance?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "RAG Analysis Result:\n",
      "\n",
      "Risk assessment in insurance is a crucial process that involves evaluating the potential risks associated with insuring an individual or a group of individuals. It helps insurance companies determine the appropriate premiums to charge and the level of coverage to provide. In this analysis, we will explore the best practices for risk assessment in insurance using the provided dataset.\n",
      "\n",
      "1. Univariate Analysis:\n",
      "The first step in risk assessment is to understand the distribution of the variables in the dataset. In this case, we have three variables - charges, BMI, and age. The most appropriate center for charges is the median, as the distribution is skewed right. The most appropriate spread is the interquartile range (IQR), and there are no outliers. For BMI, the most appropriate center is the mean, as the distribution is normal. The most appropriate spread is the standard deviation, and there are no outliers. For age, the most appropriate center is also the mean, as it is uniformly distributed. The most appropriate spread is the standard deviation, and there are no outliers.\n",
      "\n",
      "2. Univariate Analysis by Groups:\n",
      "Next, we can analyze the variables by different groups to understand their impact on insurance charges. From the box plots, we can see that smokers tend to pay higher insurance charges compared to non-smokers.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run the entire analysis system\"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        data = pd.read_csv('insurance.csv')\n",
    "        print(\"Data loaded successfully\")\n",
    "        \n",
    "        # Initialize analyzers\n",
    "        univariate_analyzer = UnivariateAnalyzer(data)\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ValueError(\"OpenAI API key not found in environment variables\")\n",
    "        llm_analyzer = LLMAnalyzer(api_key)\n",
    "        print(\"Analyzers initialized\")\n",
    "        \n",
    "        # Setup RAG system\n",
    "        rag_status = llm_analyzer.setup_rag('analysisRag.pdf')\n",
    "        print(f\"RAG setup status: {rag_status}\")\n",
    "        \n",
    "        # Create and setup agent\n",
    "        tools = llm_analyzer.create_tools(univariate_analyzer)\n",
    "        agent = llm_analyzer.setup_agent(tools)\n",
    "        print(\"Agent setup completed\")\n",
    "        \n",
    "        # Run analysis and generate report\n",
    "        results = run_analysis_with_report(univariate_analyzer, llm_analyzer, agent)\n",
    "        print(\"Analysis completed and report generated\")\n",
    "        # Run the queries\n",
    "        run_agent_queries(univariate_analyzer, llm_analyzer, agent, data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        print(\"\\nPlease ensure:\")\n",
    "        print(\"1. 'insurance.csv' file is in the working directory\")\n",
    "        print(\"2. 'analysis_guidelines.pdf' file is in the working directory\")\n",
    "        print(\"3. OPENAI_API_KEY environment variable is set\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
